% Encoding: ISO-8859-1

@InCollection{HaneySIGMOD2017,
  author    = {Samuel Haney and Ashwin Machanavajjhala and John M. Abowd and Matthew Graham and Mark Kutzbach and Lars Vilhuber},
  title     = {Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics},
  booktitle = {Proceedings of the 2017 International Conference on Management of Data},
  publisher = {ACM},
  year      = {2017},
  volume    = {forthcoming},
  series    = {SIGMOD '17},
  abstract  = {National statistical agencies around the world publish tabular summaries based on combined employer-employee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures.
	In this work, we present novel algorithms for releasing tabular summaries of linked ER-EE data with formal, provable guarantees of privacy. We show that state-of-the-art differentially private algorithms add too much noise for the output to be useful. Instead, we identify the privacy requirements mandated by current interpretations of the relevant laws, and formalize them using the Pufferfish framework. We then develop new privacy definitions that are customized to ER-EE data and satisfy the statutory privacy requirements. We implement the experiments in this paper on production data gathered by the U.S. Census Bureau. An empirical evaluation of utility for these data shows that for reasonable values of the privacy-loss parameter $\epsilon\geq$ 1, the additive error introduced by our provably private algorithms is comparable, and in some cases better, than the error introduced by existing SDL techniques that have no provable privacy guarantees. For some complex queries currently published, however, our algorithms do not have utility comparable to the existing traditional SDL algorithms. Those queries are fodder for future research.},
  acmid     = {3035940},
  doi       = {10.1145/3035918.3035940},
  journal   = {SIGMOD},
  owner     = {vilhuber},
  timestamp = {2017.03.01},
  url       = {http://dx.doi.org/10.1145/3035918.3035940},
}

@Article{Abowd:JPC:2017,
  author    = {John M. Abowd},
  title     = {How Will Statistical Agencies Operate When All Data Are Private?},
  journal   = {Journal of Privacy and Confidentiality},
  year      = {2017},
  volume    = {7},
  number    = {3},
  abstract  = {The dual problems of respecting citizen privacy and protecting the confidentiality of their data have become hopelessly conflated in the ?Big Data? era. There are orders of magnitude more data outside an agency?s firewall than inside it-compromising the integrity of traditional statistical disclosure limitation methods. And increasingly the information processed by the agency was ?asked? in a context wholly outside the agency?s operations-blurring the distinction between what was asked and what is published. Already, private businesses like Microsoft, Google and Apple recognize that cybersecurity (safeguarding the integrity and access controls for internal data) and privacy protection (ensuring that what is published does not reveal too much about any person or business) are two sides of the same coin. This is a paradigm-shifting moment for statistical agencies.},
  owner     = {vilhuber},
  timestamp = {2017.05.03},
  url       = {http://repository.cmu.edu/jpc/vol7/iss3/1/},
}

@Article{abowd:schmutte:BPEA:2015,
  author        = {John M. Abowd and Ian M. Schmutte},
  title         = {Economic analysis and statistical disclosure limitation},
  journal       = {Brookings Papers on Economic Activity},
  year          = {2015},
  pages         = {221--267},
  note          = {Spring},
  __markedentry = {[vilhuber:6]},
  owner         = {John Abowd},
  timestamp     = {2016.07.08},
  xurl          = {http://www.brookings.edu/~/media/Projects/BPEA/Spring-2015-Revised/AbowdText.pdf?la=en},
}

@TechReport{Abowd:LDI:2016:30,
  author      = {John M. Abowd},
  title       = {How Will Statistical Agencies Operate When All Data Are Private?},
  institution = {Labor Dynamics Institute, Cornell University},
  year        = {2016},
  type        = {Document},
  number      = {30},
  abstract    = {The dual problems of respecting citizen privacy and protecting the confidentiality of their data have become hopelessly conflated in the ?Big Data? era. There are orders of magnitude more data outside an agency?s firewall than inside it-compromising the integrity of traditional statistical disclosure limitation methods. And increasingly the information processed by the agency was ?asked? in a context wholly outside the agency?s operations-blurring the distinction between what was asked and what is published. Already, private businesses like Microsoft, Google and Apple recognize that cybersecurity (safeguarding the integrity and access controls for internal data) and privacy protection (ensuring that what is published does not reveal too much about any person or business) are two sides of the same coin. This is a paradigm-shifting moment for statistical agencies.},
  owner       = {vilhuber},
  timestamp   = {2017.05.03},
  xurl        = {http://digitalcommons.ilr.cornell.edu/ldi/30/},
}

@TechReport{Vilhuber:LDI:2017:33,
  author      = {Vilhuber, Lars and Schmutte, Ian M. and Abowd, John M.},
  title       = {Proceedings from the 2016 NSF-Sloan Workshop on Practical Privacy},
  institution = {Labor Dynamics Institute, Cornell University},
  year        = {2017},
  type        = {Document},
  number      = {33},
  abstract    = {On October 14, 2016, we hosted a workshop that brought together economists, survey statisticians, and computer scientists with expertise in the field of privacy preserving methods: Census Bureau staff working on implementing cutting-edge methods in the Bureau?s flagship public-use products mingled with academic researchers from a variety of universities. The four products discussed as part of the workshop were 1. the American Community Survey (ACS); 2. Longitudinal Employer-Household Data (LEHD), in particular the LEHD Origin-Destination Employment Statistics (LODES); the 3. 2020 Decennial Census; and the 4. 2017 Economic Census. The goal of the workshop was to 1. Discuss the specific challenges that have arisen in ongoing efforts to apply formal privacy models to Census data products by drawing together expertise of academic and governmental researchers 2. Produce short written memos that summarize concrete suggestions for practical applications to specific Census Bureau priority areas.

Funding for the workshop was provided by the National Science Foundation (CNS-1012593) and the Alfred P. Sloan Foundation. Organizational support was provided by the Research and Methodology Directorate at the U.S. Census Bureau and the Labor Dynamics Institute at Cornell University.},
  comment     = {Funding by National Science Foundation (CNS-1012593) and the Alfred P. Sloan Foundation},
  owner       = {vilhuber},
  timestamp   = {2017.05.03},
  url         = {http://digitalcommons.ilr.cornell.edu/ldi/33/},
  xurl        = {http://digitalcommons.ilr.cornell.edu/ldi/33/},
}

@TechReport{handle:1813:44663,
  author      = {Abowd, John M.},
  title       = {How Will Statistical Agencies Operate When All Data Are Private?},
  institution = {Cornell University},
  year        = {2016},
  type        = {Preprint},
  number      = {1813:44663},
  abstract    = {How Will Statistical Agencies Operate When All Data Are Private? Abowd, John M. The dual problems of respecting citizen privacy and protecting the confidentiality of their data have become hopelessly conflated in the {\textquotedblleft}Big Data{\textquotedblright} era. There are orders of magnitude more data outside an agency{\textquoteright}s firewall than inside it{\textemdash}compromising the integrity of traditional statistical disclosure limitation methods. And increasingly the information processed by the agency was {\textquotedblleft}asked{\textquotedblright} in a context wholly outside the agency{\textquoteright}s operations{\textemdash}blurring the distinction between what was asked and what is published. Already, private businesses like Microsoft, Google and Apple recognize that cybersecurity (safeguarding the integrity and access controls for internal data) and privacy protection (ensuring that what is published does not reveal too much about any person or business) are two sides of the same coin. This is a paradigm-shifting moment for statistical agencies.},
  owner       = {vilhuber},
  timestamp   = {2017.10.02},
  url         = {http://hdl.handle.net/1813/44663},
}

@Article{2240,
  author    = {Abowd, John M. and McKinney, Kevin L.},
  title     = {Noise infusion as a confidentiality protection measure for graph-based statistics},
  journal   = {Statistical Journal of the International Association for Official Statistics},
  year      = {2016},
  volume    = {32},
  pages     = {127-135},
  abstract  = {We use the bipartite graph representation of longitudinally linked employer-employee data, and the associated projections onto the employer and employee nodes, respectively, to characterize the set of potential statistical summaries that the trusted custodian might produce. We consider noise infusion as the primary confidentiality protection method. We show that a relatively straightforward extension of the dynamic noise-infusion method used in the U.S. Census Bureau{\textquoteright}s Quarterly Workforce Indicators can be adapted to provide the same confidentiality guarantees for the graph-based statistics: all inputs have been modified by a minimum percentage deviation (i.e., no actual respondent data are used) and, as the number of entities contributing to a particular statistic increases, the accuracy of that statistic approaches the unprotected value. Our method also ensures that the protected statistics will be identical in all releases based on the same inputs.},
  chapter   = {127},
  doi       = {10.3233/SJI-160958},
  owner     = {vilhuber},
  timestamp = {2017.10.02},
  url       = {http://content.iospress.com/articles/statistical-journal-of-the-iaos/sji958},
}

@Article{Schmutte:Differentially:SJIAOS:2016,
  author    = {Schmutte, Ian M.},
  title     = {Differentially private publication of data on wages and job mobility},
  journal   = {Statistical Journal of the International Association for Official Statistics},
  year      = {2016},
  volume    = {32},
  number    = {1},
  pages     = {81-92},
  month     = {02/2016/2016},
  abstract  = {Brazil, like many countries, is reluctant to publish business-level data, because of legitimate concerns about the establishments{\textquoteright} confidentiality. A trusted data curator can increase the utility of data, while managing the risk to establishments, either by releasing synthetic data, or by infusing noise into published statistics. This paper evaluates the application of a differentially private mechanism to publish statistics on wages and job mobility computed from Brazilian employer-employee matched data. The publication mechanism can result in both the publication of specific statistics as well as the generation of synthetic data. I find that the tradeoff between the privacy guaranteed to individuals in the data, and the accuracy of published statistics, is potentially much better that the worst-case theoretical accuracy guarantee. However, the synthetic data fare quite poorly in analyses that are outside the set of queries to which it was trained. Note that this article only explores and characterizes the feasibility of these publication strategies, and will not directly result in the publication of any data. },
  doi       = {10.3233/SJI-160962},
  keywords  = {Demand for public statistics, differential privacy, job mobility, matched employer-employee data, optimal confidentiality protection, optimal data accuracy, technology for statistical agencies},
  owner     = {vilhuber},
  timestamp = {2017.10.02},
  url       = {http://content.iospress.com/articles/statistical-journal-of-the-iaos/sji962},
}

@Article{VilhuberAbowdReiter:Synthetic:SJIAOS:2016,
  author    = {Vilhuber, Lars and Abowd, John M. and Reiter, Jerome P.},
  title     = {Synthetic establishment microdata around the world},
  journal   = {Statistical Journal of the International Association for Official Statistics},
  year      = {2016},
  volume    = {32},
  number    = {1},
  pages     = {65-68},
  abstract  = {In contrast to the many public-use microdata samples available for individual and household data from many statistical agencies around the world, there are virtually no establishment or firm microdata available. In large part, this difficulty in providing access to business micro data is due to the skewed and sparse distributions that characterize business data. Synthetic data are simulated data generated from statistical models. We organized sessions at the 2015 World Statistical Congress and the 2015 Joint Statistical Meetings, highlighting work on synthetic establishment microdata. This overview situates those papers, published in this issue, within the broader literature.},
  doi       = {10.3233/SJI-160964},
  keywords  = {Business data, confidentiality, differential privacy, international comparison, Multiple imputation, synthetic},
  owner     = {vilhuber},
  timestamp = {2017.10.02},
  url       = {http://content.iospress.com/download/statistical-journal-of-the-iaos/sji964},
}

@Article{MirandaVilhuber:Using:SJIAOS:2016,
  author    = {Miranda, Javier and Vilhuber, Lars},
  title     = {Using partially synthetic microdata to protect sensitive cells in business statistics},
  journal   = {Statistical Journal of the International Association for Official Statistics},
  year      = {2016},
  volume    = {32},
  number    = {1},
  pages     = {69-80},
  month     = {2016},
  abstract  = {We describe and analyze a method that blends records from both observed and synthetic microdata into public-use tabulations on establishment statistics. The resulting tables use synthetic data only in potentially sensitive cells. We describe different algorithms, and present preliminary results when applied to the Census Bureau's Business Dynamics Statistics and Synthetic Longitudinal Business Database, highlighting accuracy and protection afforded by the method when compared to existing public-use tabulations (with suppressions).},
  doi       = {10.3233/SJI-160963},
  keywords  = {confidentiality protection, gross job flows, local labor markets, Statistical Disclosure Limitation, Synthetic data, time-series},
  owner     = {vilhuber},
  timestamp = {2017.10.02},
  url       = {http://content.iospress.com/download/statistical-journal-of-the-iaos/sji963},
}

@TechReport{Abowd:LDI:2016:32,
  author      = {Abowd, John M.},
  title       = {Why Statistical Agencies Need to Take Privacy-loss Budgets Seriously, and What It Means When They Do},
  institution = {Labor Dynamics Institute, Cornell University},
  year        = {2016},
  type        = {Document},
  number      = {32},
  abstract    = {To appear on fcsm.sites.usa.gov, as presented to the 2016 FCSM Statistical Policy Seminar.},
  owner       = {vilhuber},
  timestamp   = {2017.10.02},
  url         = {http://digitalcommons.ilr.cornell.edu/ldi/32/},
  xurl        = {http://digitalcommons.ilr.cornell.edu/ldi/32/},
}

@Article{annalsSorting,
  author        = {John M. Abowd and Francis Kramarz and Sebastien Perez-Duarte and Ian M. Schmutte},
  title         = {Sorting Between and Within Industries: A Testable Model of Assortative Matching},
  journal       = {Annals of Economics and Statistics},
  year          = {2018},
  issn          = {21154430, 19683863},
  __markedentry = {[vilhuber:6]},
  owner         = {vilhuber},
  timestamp     = {2017.09.21},
}

@TechReport{ldi40,
  author      = {John M. Abowd and Francis Kramarz and Sebastien Perez-Duarte and Ian M. Schmutte},
  title       = {Sorting Between and Within Industries: A Testable Model of Assortative Matching},
  institution = {Labor Dynamics Institute},
  year        = {2017},
  type        = {Document},
  number      = {40},
  abstract    = {We test Shimer's (2005) theory of the sorting of workers between and within industrial sectors based on directed search with coordination frictions, deliberately maintaining its static general equilibrium framework. We fit the model to sector-specific wage, vacancy and output data, including publicly-available statistics that characterize the distribution of worker and employer wage heterogeneity across sectors. Our empirical method is general and can be applied to a broad class of assignment models. The results indicate that industries are the loci of sorting--more productive workers are employed in more productive industries. The evidence confirms that strong assortative matching can be present even when worker and employer components of wage heterogeneity are weakly correlated.},
  owner       = {vilhuber},
  timestamp   = {2017.09.21},
  url         = {http://digitalcommons.ilr.cornell.edu/ldi/28/},
}

@Article{jole2018,
  author    = {John M. Abowd and Kevin L. Mckinney and Nellie Zhao},
  title     = {Earnings Inequality and Mobility Trends in the United States: Nationally Representative Estimates from Longitudinally Linked Employer-Employee Data},
  journal   = {Journal of Labor Economics},
  year      = {2018},
  abstract  = {Using earnings data from the U.S. Census Bureau, this paper analyzes the role of the employer in explaining the rise in earnings inequality in the United States. We first establish a consistent frame of analysis appropriate for administrative data used to study earnings inequality. We show that the trends in earnings inequality in the administrative data from the Longitudinal Employer-Household Dynamics Program are inconsistent with other data sources when we do not correct for the presence of misused SSNs. After this correction to the worker frame, we analyze how the earnings distribution has changed in the last decade. We present a decomposition of the year-to-year changes in the earnings distribution from 2004-2013. Even when simplifying these flows to movements between the bottom 20\%, the middle 60\% and the top 20\% of the earnings distribution, about 20.5 million workers undergo a transition each year. Another 19.9 million move between employment and nonemployment. To understand the role of the firm in these transitions, we estimate a model for log earnings with additive fixed worker and firm effects using all jobs held by eligible workers from 2004-2013. We construct a composite log earnings firm component across all jobs for a worker in a given year and a non-firm component. We also construct a skill-type index. We show that, while the difference between working at a low- or middle-paying firm are relatively small, the gains from working at a top-paying firm are large. Specifically, the benefits of working for a high-paying firm are not only realized today, through higher earnings paid to the worker, but also persist through an increase in the probability of upward mobility. High-paying firms facilitate moving workers to the top of the earnings distribution and keeping them there.},
  owner     = {vilhuber},
  timestamp = {2017.09.21},
}

@TechReport{ldi37,
  author      = {John M. Abowd and Ian M. Schmutte},
  title       = {Revisiting the Economics of Privacy: Population Statistics and Confidentiality Protection as Public Goods},
  institution = {Labor Dynamics Institute},
  year        = {2017},
  type        = {Document},
  number      = {37},
  month       = {04/2017},
  abstract    = {We consider the problem of determining the optimal accuracy of public statistics when increased accuracy requires a loss of privacy. To formalize this allocation problem, we use tools from statistics and computer science to model the publication technology used by a public statistical agency. We derive the demand for accurate statistics from first principles to generate interdependent preferences that account for the public-good nature of both data accuracy and privacy loss. We first show data accuracy is inefficiently under-supplied by a private provider. Solving the appropriate social planner{\textquoteright}s problem produces an implementable publication strategy. We implement the socially optimal publication plan for statistics on income and health status using data from the American Community Survey, National Health Interview Survey, Federal Statistical System Public Opinion Survey and Cornell National Social Survey. Our analysis indicates that welfare losses from providing too much privacy protection and, therefore, too little accuracy can be substantial.},
  owner       = {vilhuber},
  timestamp   = {2017.10.02},
  url         = {http://digitalcommons.ilr.cornell.edu/ldi/37/},
}

@Article{2541,
  author    = {Samuel Haney and Ashwin Machanavajjhala and John M. Abowd and Matthew Graham and Mark Kutzbach},
  title     = {Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics},
  journal   = {Proceedings of the 2017 ACM International Conference on Management of Data},
  year      = {2017},
  abstract  = {National statistical agencies around the world publish tabular summaries based on combined employer-employee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures.

In this work, we present novel algorithms for releasing tabular summaries of linked ER-EE data with formal, provable guarantees of privacy. We show that state-of-the-art differentially private algorithms add too much noise for the output to be useful. Instead, we identify the privacy requirements mandated by current interpretations of the relevant laws, and formalize them using the Pufferfish framework. We then develop new privacy definitions that are customized to ER-EE data and satisfy the statutory privacy requirements. We implement the experiments in this paper on production data gathered by the U.S. Census Bureau. An empirical evaluation of utility for these data shows that for reasonable values of the privacy-loss parameter ε>= 1, the additive error introduced by our provably private algorithms is comparable, and in some cases better, than the error introduced by existing SDL techniques that have no provable privacy guarantees. For some complex queries currently published, however, our algorithms do not have utility comparable to the existing traditional SDL algorithms. Those queries are fodder for future research.},
  doi       = {10.1145/3035918.3035940},
  isbn      = {978-1-4503-4197-4},
  owner     = {vilhuber},
  timestamp = {2017.10.02},
  url       = {http://dl.acm.org/citation.cfm?doid=3035918.3035940},
}

@TechReport{handle:1813:49652,
  author      = {Haney, Samuel and Machanavajjhala, Ashwin and Abowd, John M and Graham, Matthew and Kutzbach, Mark},
  title       = {Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics},
  institution = {Cornell University},
  year        = {2017},
  type        = {Preprint},
  number      = {1813:49652},
  abstract    = {Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics Haney, Samuel; Machanavajjhala, Ashwin; Abowd, John M; Graham, Matthew; Kutzbach, Mark National statistical agencies around the world publish tabular summaries based on combined employeremployee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures. In this work, we present novel algorithms for releasing tabular summaries of linked ER-EE data with formal, provable guarantees of privacy. We show that state-of-the-art differentially private algorithms add too much noise for the output to be useful. Instead, we identify the privacy requirements mandated by current interpretations of the relevant laws, and formalize them using the Pufferfish framework. We then develop new privacy definitions that are customized to ER-EE data and satisfy the statutory privacy requirements. We implement the experiments in this paper on production data gathered by the U.S. Census Bureau. An empirical evaluation of utility for these data shows that for reasonable values of the privacy-loss parameter ϵ>=1, the additive error introduced by our provably private algorithms is comparable, and in some cases better, than the error introduced by existing SDL techniques that have no provable privacy guarantees. For some complex queries currently published, however, our algorithms do not have utility comparable to the existing traditional \&quot;This Article is brought to you for free and open access by the Centers, Institutes, Programs at DigitalCommons@ILR. It has been accepted for inclusion in Labor Dynamics Institute by an authorized administrator of DigitalCommons@ILR. For more information, please contact hlmdigital@cornell.edu.\&quot;},
  owner       = {vilhuber},
  timestamp   = {2017.10.02},
  url         = {http://hdl.handle.net/1813/49652},
}

@TechReport{ProceedingsSynLBD2017,
  author      = {Lars Vilhuber and Saki Kinney and Ian Schmutte},
  title       = {Proceedings from the Synthetic LBD International Seminar},
  institution = {Labor Dynamics Institute, Cornell University},
  year        = {2017},
  type        = {Document},
  number      = {44},
  abstract    = {On May 9, 2017, we hosted a seminar to discuss the conditions necessary to implement the SynLBD approach with interested parties, with the goal of providing a straightforward toolkit to implement the same procedure on other data. The proceedings summarize the discussions during the workshop.
Funding for the workshop was provided by the National Science Foundation (Grants 1012593; 1131848) and the Alfred P. Sloan Foundation (G-2015-13903). Organizational support was provided by the Labor Dynamics Institute at Cornell University.},
  owner       = {vilhuber},
  timestamp   = {2017.09.28},
  url         = {http://digitalcommons.ilr.cornell.edu/ldi/44/},
}

@TechReport{VilhuberLagozeLDI2017,
  author      = {Lars Vilhuber and Carl Lagoze},
  title       = {Making Confidential Data Part of Reproducible Research},
  institution = {Labor Dynamics Institute, Cornell University},
  year        = {2017},
  type        = {Document},
  number      = {41},
  owner       = {vilhuber},
  timestamp   = {2017.09.28},
  url         = {http://digitalcommons.ilr.cornell.edu/ldi/41/},
}

@Article{chance:2017,
  author    = {Vilhuber, Lars and Lagoze, Carl},
  title     = {Making Confidential Data Part of Reproducible Research},
  journal   = {Chance},
  year      = {2017},
  month     = {09/2017},
  owner     = {vilhuber},
  timestamp = {2017.10.02},
  url       = {http://chance.amstat.org/2017/09/reproducible-research/},
}

@TechReport{handle:1813:46197,
  author      = {Vilhuber, Lars and Schmutte, Ian},
  title       = {Proceedings from the 2016 NSF-Sloan Workshop on Practical Privacy},
  institution = {Cornell University},
  year        = {2017},
  type        = {Preprint},
  number      = {1813:46197},
  abstract    = {Proceedings from the 2016 NSF{\textendash}Sloan Workshop on Practical Privacy Vilhuber, Lars; Schmutte, Ian; Abowd, John M. On October 14, 2016, we hosted a workshop that brought together economists, survey statisticians, and computer scientists with expertise in the field of privacy preserving methods: Census Bureau staff working on implementing cutting-edge methods in the Bureau{\textquoteright}s flagship public-use products mingled with academic researchers from a variety of universities. The four products discussed as part of the workshop were 1. the American Community Survey (ACS); 2. Longitudinal Employer-Household Data (LEHD), in particular the LEHD Origin-Destination Employment Statistics (LODES); the 3. 2020 Decennial Census; and the 4. 2017 Economic Census. The goal of the workshop was to 1. Discuss the specific challenges that have arisen in ongoing efforts to apply formal privacy models to Census data products by drawing together expertise of academic and governmental researchers 2. Produce short written memos that summarize concrete suggestions for practical applications to specific Census Bureau priority areas.},
  owner       = {vilhuber},
  timestamp   = {2017.10.02},
  url         = {http://hdl.handle.net/1813/46197},
}

@TechReport{ProceedingsNSFSloan2017,
  author      = {Lars Vilhuber and Ian Schmutte},
  title       = {Proceedings from the 2017 Cornell-Census-NSF-Sloan Workshop on Practical Privacy},
  institution = {Labor Dynamics Institute, Cornell University},
  year        = {2017},
  type        = {Document},
  number      = {43},
  abstract    = {These proceedings report on a workshop hosted at the U.S. Census Bureau on May 8, 2017. Our purpose was to gather experts from various backgrounds together to continue discussing the development of formal privacy systems for Census Bureau data products. This workshop was a successor to a previous workshop held in October 2016 (Vilhuber & Schmutte 2017). At our prior workshop, we hosted computer scientists, survey statisticians, and economists, all of whom were experts in data privacy. At that time we discussed the practical implementation of cutting-edge methods for publishing data with formal, provable privacy guarantees, with a focus on applications to Census Bureau data products. The teams developing those applications were just starting out when our first workshop took place, and we spent our time brainstorming solutions to the various problems researchers were encountering, or anticipated encountering. For these cutting-edge formal privacy models, there had been very little effort in the academic literature to apply those methods in real-world settings with large, messy data. We therefore brought together an expanded group of specialists from academia and government who could shed light on technical challenges, subject matter challenges and address how data users might react to changes in data availability and publishing standards.
In May 2017, we organized a follow-up workshop, which these proceedings report on. We reviewed progress made in four different areas. The four topics discussed as part of the workshop were 1. the 2020 Decennial Census; 2. the American Community Survey (ACS); 3. the 2017 Economic Census; 4. measuring the demand for privacy and for data quality.
As in our earlier workshop, our goals were to 1. Discuss the specific challenges that have arisen in ongoing efforts to apply formal privacy models to Census data products by drawing together expertise of academic and governmental researchers; 2. Produce short written memos that summarize concrete suggestions for practical applications to specific Census Bureau priority areas.},
  owner       = {vilhuber},
  timestamp   = {2017.09.28},
  url         = {http://digitalcommons.ilr.cornell.edu/ldi/43/},
}

@Comment{jabref-meta: databaseType:bibtex;}
